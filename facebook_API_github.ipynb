{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facebook_API_github",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPirOpNK7sjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pythainlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6fibU9m8NsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from pythainlp.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGkLmvXA_c5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ACCESS_TOKEN = 'EAAhtIDv5cDMBAEoZCJd81OOUKbhjVQcqLxtK6gJ1JM43pL2rtCaJByQfWo10b2dZB9OFhXleMHot7lQe7zTurcafLVS4sLNJZCMA9Ylfw5KSQYfqXYNUWtdEbquzahgzTnPojv8mPLOjxMPdAFZAZBtfxa25PEVYSZB6R5QV6Kdu71RnfyYIR9djZBU7sAF9IdgmKNPZCYZAGUlui0jS19X6v7a4Ed6cAsUHN3GhlZCvSitIusFha1Fsqq'\n",
        "page_name = 'Me'\n",
        "base_url = 'https://graph.facebook.com/v5.0/'+page_name\n",
        "fields = 'posts{message,full_picture,created_time,shares,reactions.summary(true),comments.summary(true),permalink_url}'\n",
        "url = '%s?fields=%s&access_token=%s' % (base_url,fields,ACCESS_TOKEN)\n",
        "print(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mijj61QcEIDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content = requests.get(url).json()\n",
        "list_feed = [f for f in content['posts']['data']]\n",
        "df = pd.DataFrame()\n",
        "while True:\n",
        "    m = ''\n",
        "    for f in list_feed:\n",
        "        new_record = dict()\n",
        "        if 'message' not in f:\n",
        "            new_record['message'] = 'n/a'\n",
        "            m = 'n/a'\n",
        "        else:\n",
        "            t_str = ' '.join(str(f['message']).split('\\r'))\n",
        "            m = ' '.join(t_str.split('\\n'))\n",
        "            tokenized_sentence = ''\n",
        "            for tokens in m.split():\n",
        "                if 'http' in tokens:\n",
        "                    tokenized_sentence += ' '+tokens\n",
        "                else:\n",
        "                    tokenized_sentence += ' '+' '.join(word_tokenize(tokens))\n",
        "            new_record['message'] = tokenized_sentence\n",
        "            m = tokenized_sentence\n",
        "        print(f['created_time'])\n",
        "        if 'reactions' in f:\n",
        "            print(f['reactions']['summary']['total_count'])\n",
        "            new_record['reactions'] = f['reactions']['summary']['total_count']\n",
        "            new_record['comments'] = f['comments']['summary']['total_count']\n",
        "            new_record['created_time'] = f['created_time']\n",
        "            if 'shares' in f:\n",
        "                new_record['shares'] = f['shares']['count']\n",
        "            else:\n",
        "                new_record['shares'] = 0\n",
        "            if 'permalink_url' in f:\n",
        "                new_record['permalink_url'] = f['permalink_url']\n",
        "            else:\n",
        "                new_record['permalink_url'] = 'n/a'\n",
        "        df=df.append(new_record,ignore_index=True)\n",
        "    if 'posts' in content:\n",
        "        if 'paging' not in content['posts'] or 'next' not in content['posts']['paging']: \n",
        "            break;        \n",
        "        url = content['posts']['paging']['next']\n",
        "    elif 'paging' in content:\n",
        "        if 'next' not in content['paging']:\n",
        "            break\n",
        "        url = content['paging']['next']\n",
        "    else:\n",
        "        break\n",
        "    print('Getting next posts')\n",
        "    content = requests.get(url).json()\n",
        "    list_feed = [f for f in content['data']]\n",
        "df.to_csv(page_name+'me.csv')\n",
        "from google.colab import files\n",
        "files.download(page_name+'me.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arN3axTWJMAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('Profileme.csv')\n",
        "df['created_time']=pd.to_datetime(df['created_time'])\n",
        "new_df=df.groupby(pd.Grouper(key='created_time',freq='W')) \n",
        "new_df.sum()['reactions'].plot(kind='line',color=['b'],figsize=(18,12))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}